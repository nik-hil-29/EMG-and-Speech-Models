{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7755072,"sourceType":"datasetVersion","datasetId":4534596},{"sourceId":7773840,"sourceType":"datasetVersion","datasetId":4548201},{"sourceId":7857620,"sourceType":"datasetVersion","datasetId":4608876},{"sourceId":7867029,"sourceType":"datasetVersion","datasetId":4615609}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-02T13:47:57.349615Z","iopub.execute_input":"2024-04-02T13:47:57.350574Z","iopub.status.idle":"2024-04-02T13:47:58.747675Z","shell.execute_reply.started":"2024-04-02T13:47:57.350534Z","shell.execute_reply":"2024-04-02T13:47:58.746499Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/emg-test-1/emg_test/down_test/5_18_08_09.csv\n/kaggle/input/emg-test-1/emg_test/down_test/4_18_08_04.csv\n/kaggle/input/emg-test-1/emg_test/down_test/6_18_08_16.csv\n/kaggle/input/emg-test-1/emg_test/right_test/12_18_09_07.csv\n/kaggle/input/emg-test-1/emg_test/right_test/11_18_09_00.csv\n/kaggle/input/emg-test-1/emg_test/right_test/10_18_08_52.csv\n/kaggle/input/emg-test-1/emg_test/left_test/9_18_08_40.csv\n/kaggle/input/emg-test-1/emg_test/left_test/8_18_08_33.csv\n/kaggle/input/emg-test-1/emg_test/left_test/7_18_08_26.csv\n/kaggle/input/emg-test-1/emg_test/up_test/1_18_07_38.csv\n/kaggle/input/emg-test-1/emg_test/up_test/3_18_07_52.csv\n/kaggle/input/emg-test-1/emg_test/up_test/2_18_07_44.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right46.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right3.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right25.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right76.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right49.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right85.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right48.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right58.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right64.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right8.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right97.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right28.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right14.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right57.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right67.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right37.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right72.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right100.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right87.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right77.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right1.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right59.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right74.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right56.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right69.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right55.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right51.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right96.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right4.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right70.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right22.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right88.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right78.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right18.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right5.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right6.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right90.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right98.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right47.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right39.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right30.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right9.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right21.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right7.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right24.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right34.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right42.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right32.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right68.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right66.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right11.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right84.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right2.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right54.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right26.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right13.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right33.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right81.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right94.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right16.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right62.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right12.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right43.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right17.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right52.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right40.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right80.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right36.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right50.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right91.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right45.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right71.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right63.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right99.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right31.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right53.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right35.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right92.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right61.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right73.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right65.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right82.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right15.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right89.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right19.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right79.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right60.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right95.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right75.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right10.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right83.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right93.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right41.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right38.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right29.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right20.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right86.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right27.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right23.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/right/right44.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left28.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left31.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left62.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left59.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left98.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left37.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left19.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left43.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left10.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left84.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left57.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left46.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left97.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left54.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left5.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left53.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left90.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left26.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left64.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left76.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left7.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left60.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left73.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left92.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left34.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left67.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left74.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left79.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left25.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left95.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left69.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left9.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left80.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left33.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left58.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left68.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left15.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left49.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left32.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left21.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left47.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left89.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left55.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left27.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left23.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left14.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left48.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left41.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left50.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left3.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left99.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left65.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left77.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left87.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left91.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left30.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left71.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left35.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left12.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left81.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left1.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left2.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left72.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left83.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left70.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left42.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left11.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left22.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left6.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left94.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left29.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left16.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left36.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left45.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left78.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left38.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left63.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left61.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left56.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left51.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left17.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left13.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left18.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left100.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left4.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left52.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left39.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left88.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left44.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left8.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left82.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left24.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left85.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left20.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left40.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left86.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left96.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left75.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left66.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/left/left93.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down86.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down48.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down67.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down70.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down63.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down46.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down65.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down5.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down68.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down64.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down74.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down28.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down56.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down100.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down25.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down36.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down72.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down73.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down21.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down42.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down75.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down37.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down38.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down96.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down19.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down83.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down87.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down53.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down10.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down29.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down71.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down23.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down26.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down30.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down77.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down33.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down61.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down76.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down15.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down41.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down51.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down94.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down1.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down57.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down39.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down4.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down80.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down11.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down95.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down44.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down9.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down13.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down58.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down90.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down97.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down85.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down62.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down69.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down59.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down81.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down7.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down93.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down91.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down84.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down89.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down6.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down40.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down88.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down27.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down12.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down52.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down99.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down2.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down98.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down60.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down82.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down45.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down34.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down79.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down54.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down18.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down47.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down32.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down24.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down55.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down8.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down14.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down17.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down66.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down35.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down43.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down50.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down31.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down22.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down49.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down78.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down16.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down3.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down92.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/down/down20.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up89.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up50.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up2.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up10.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up87.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up48.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up84.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up72.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up92.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up53.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up46.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up100.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up19.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up41.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up90.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up54.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up57.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up85.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up22.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up55.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up40.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up16.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up36.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up8.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up64.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up13.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up77.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up78.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up23.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up63.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up69.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up81.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up86.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up21.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up45.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up44.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up74.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up83.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up71.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up42.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up75.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up11.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up4.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up39.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up66.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up14.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up76.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up70.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up79.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up26.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up58.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up94.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up20.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up59.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up7.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up12.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up61.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up25.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up33.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up15.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up17.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up6.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up95.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up38.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up96.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up82.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up80.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up49.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up97.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up88.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up29.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up32.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up28.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up30.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up5.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up52.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up47.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up9.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up3.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up35.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up51.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up27.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up98.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up93.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up65.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up62.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up73.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up67.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up24.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up18.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up43.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up34.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up56.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up37.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up31.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up1.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up60.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up91.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up68.csv\n/kaggle/input/emg-fin-csv/emg_dataset_final/up/up99.csv\n/kaggle/input/emg-fin/emg_signals_up.h5\n/kaggle/input/emg-fin/emg_signals_left.h5\n/kaggle/input/emg-fin/emg_signals_right.h5\n/kaggle/input/emg-fin/emg_signals_down.h5\n/kaggle/input/emg-fin-model-pth/attention_model.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"import h5py\n\n# Define the paths to your HDF5 files\nfile_paths = [\n    \"/kaggle/input/emg-fin/emg_signals_up.h5\",\n   \n]\n\n# Function to get dimensions of HDF5 dataset\ndef get_dataset_dimensions(file_path):\n    with h5py.File(file_path, 'r') as file:\n        dataset = file['emg_signal_up_1']  # Replace 'dataset_name' with the actual dataset name in your HDF5 file\n        return dataset.shape\n\n# Iterate over each file and print its dimensions\nfor path in file_paths:\n    dimensions = get_dataset_dimensions(path)\n    print(f\"Dimensions of {path}: {dimensions}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T18:47:49.729935Z","iopub.execute_input":"2024-03-16T18:47:49.730868Z","iopub.status.idle":"2024-03-16T18:47:49.916680Z","shell.execute_reply.started":"2024-03-16T18:47:49.730830Z","shell.execute_reply":"2024-03-16T18:47:49.915683Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Dimensions of /kaggle/input/emg-fin/emg_signals_up.h5: (8, 1000, 7)\n","output_type":"stream"}]},{"cell_type":"code","source":"import h5py\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass EMGDataset(Dataset):\n    def __init__(self, file_paths):\n        self.all_features = []\n        self.all_labels = []\n\n        for file_path in file_paths:\n            with h5py.File(file_path, 'r') as file:\n                for key in file.keys():\n                    data = torch.tensor(file[key][:] ,  dtype=torch.float32)  # Load data into PyTorch tensor\n                    features = data[:, :, :6]  # Extract features (first 6 columns)\n                    labels = data[:, :, 6]     # Extract labels (7th column)\n\n                    self.all_features.append(features)\n                    self.all_labels.append(labels)\n\n        # Concatenate all features and labels\n        self.all_features = torch.cat(self.all_features, dim=0)\n        self.all_labels = torch.cat(self.all_labels, dim=0)\n\n    def __len__(self):\n        return len(self.all_features)\n\n    def __getitem__(self, idx):\n        return self.all_features[idx], self.all_labels[idx] # Convert labels to long (int) type\n\n\n# Define the paths to your HDF5 files\nfile_paths = [\n    \"/kaggle/input/emg-fin/emg_signals_up.h5\",\n    \"/kaggle/input/emg-fin/emg_signals_left.h5\",\n    \"/kaggle/input/emg-fin/emg_signals_right.h5\",\n    \"/kaggle/input/emg-fin/emg_signals_down.h5\"\n]\n\n# Create dataset\ndataset = EMGDataset(file_paths)\n\n# Split the dataset into train, validation, and test sets\ntrain_ratio = 0.7\nval_ratio = 0.15\ntest_ratio = 0.15\n\ntrain_size = int(train_ratio * len(dataset))\nval_size = int(val_ratio * len(dataset))\ntest_size = len(dataset) - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n    dataset, [train_size, val_size, test_size])\n\n# Create DataLoader for train, validation, and test sets\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Example: Iterating over the train loader\nfor features, labels in train_loader:\n    print(\"Train Data Shapes:\", features.shape, labels.shape)\n    break  # Breaking after one iteration for demonstration\n\n# Example: Iterating over the validation loader\nfor features, labels in val_loader:\n    print(\"Validation Data Shapes:\", features.shape, labels.shape)\n    break  # Breaking after one iteration for demonstration\n\n# Example: Iterating over the test loader\nfor features, labels in test_loader:\n    print(\"Test Data Shapes:\", features.shape, labels.shape)\n    break  # Breaking after one iteration for demonstration\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:50:55.026780Z","iopub.execute_input":"2024-04-02T13:50:55.027220Z","iopub.status.idle":"2024-04-02T13:50:57.517026Z","shell.execute_reply.started":"2024-04-02T13:50:55.027189Z","shell.execute_reply":"2024-04-02T13:50:57.515135Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Train Data Shapes: torch.Size([32, 1000, 6]) torch.Size([32, 1000])\nValidation Data Shapes: torch.Size([32, 1000, 6]) torch.Size([32, 1000])\nTest Data Shapes: torch.Size([32, 1000, 6]) torch.Size([32, 1000])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Attention(nn.Module):\n    def __init__(self, input_dim):\n        super(Attention, self).__init__()\n        self.input_dim = input_dim\n        self.W = nn.Linear(input_dim, input_dim)\n        self.v = nn.Linear(input_dim, 1, bias=False)\n\n    def forward(self, encoder_outputs):\n        energy = torch.tanh(self.W(encoder_outputs))\n        attention_scores = self.v(energy).squeeze(dim=-1)\n        attention_weights = F.softmax(attention_scores, dim=-1)\n        context_vector = torch.sum(encoder_outputs * attention_weights.unsqueeze(-1), dim=1)\n        return context_vector, attention_weights\n\n\nclass EMGAttentionModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, bidirectional, num_classes):\n        super(EMGAttentionModel, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.bidirectional = bidirectional\n        self.num_classes = num_classes\n\n        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=0.2, bidirectional=bidirectional)\n        self.attention = Attention(hidden_size * 2 if bidirectional else hidden_size)\n        self.fc1 = nn.Linear(hidden_size * 2 if bidirectional else hidden_size, 256)  # Increase output size\n        self.fc2 = nn.Linear(256, 128)  # New fully connected layer\n        self.fc3 = nn.Linear(128, num_classes)  # New fully connected layer\n        self.dropout = nn.Dropout(0.5)\n        self.layer_norm = nn.LayerNorm(hidden_size * 2 if bidirectional else hidden_size)\n\n    def forward(self, x):\n        rnn_outputs, _ = self.rnn(x)\n        rnn_outputs = self.layer_norm(rnn_outputs)  # Apply layer normalization\n        context_vector, _ = self.attention(rnn_outputs)\n        x = torch.relu(self.fc1(self.dropout(context_vector)))\n        x = torch.relu(self.fc2(self.dropout(x)))  # Apply ReLU to the output of the new layer\n        x = self.fc3(x)\n        return x\n\n# Define the input size and number of classes\ninput_size = 6  # Number of features in the input data\nhidden_size = 64  # Hidden size of the LSTM and attention mechanism\nnum_layers = 6  # Increase the number of LSTM layers\nbidirectional = True  # Whether to use bidirectional LSTMs\nnum_classes = 4  # Number of classes (0, 1, 2, 3)\n\n# Initialize the model\nattention_model = EMGAttentionModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional, num_classes=num_classes)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T09:19:33.414255Z","iopub.execute_input":"2024-04-16T09:19:33.414589Z","iopub.status.idle":"2024-04-16T09:19:37.241874Z","shell.execute_reply.started":"2024-04-16T09:19:33.414561Z","shell.execute_reply":"2024-04-16T09:19:37.240795Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"attention_model","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:48:08.932322Z","iopub.execute_input":"2024-04-02T13:48:08.932942Z","iopub.status.idle":"2024-04-02T13:48:08.944064Z","shell.execute_reply.started":"2024-04-02T13:48:08.932907Z","shell.execute_reply":"2024-04-02T13:48:08.942677Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"EMGAttentionModel(\n  (rnn): LSTM(6, 64, num_layers=6, batch_first=True, dropout=0.2, bidirectional=True)\n  (attention): Attention(\n    (W): Linear(in_features=128, out_features=128, bias=True)\n    (v): Linear(in_features=128, out_features=1, bias=False)\n  )\n  (fc1): Linear(in_features=128, out_features=256, bias=True)\n  (fc2): Linear(in_features=256, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\ndef train_model_attention(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, model_path='attention_model.pth'):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Get the device\n    model.to(device)  # Move model to GPU if available\n    \n    # Load the model state if available\n    if os.path.exists(model_path):\n        model.load_state_dict(torch.load(model_path))\n        print(f\"Model loaded from {model_path}\")\n    \n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        correct_predictions = 0\n        total_samples = 0\n        \n        for features, labels in train_loader:\n            features, labels = features.to(device), labels.to(device)  # Move data to GPU\n            optimizer.zero_grad()\n            outputs = model(features)\n            \n            # Flatten the predictions to 2D tensor (batch_size * sequence_length, num_classes)\n            outputs_flattened = outputs.view(-1, outputs.shape[-1])\n            \n            # Extract the last label in each sequence\n            last_labels = labels[:, -1].long()  # Convert to torch.long\n            \n            # Calculate loss\n            loss = criterion(outputs_flattened, last_labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            \n            # Calculate accuracy\n            _, predicted = torch.max(outputs, 1)\n            correct_predictions += (predicted == last_labels).sum().item()\n            total_samples += labels.size(0)\n        \n        avg_train_loss = running_loss / len(train_loader)\n        train_accuracy = correct_predictions / total_samples\n        \n        # Print the average training loss and accuracy\n        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n\n        # Validation\n        model.eval()  # Set the model to evaluation mode\n        val_correct_predictions = 0\n        val_total_samples = 0\n        \n        with torch.no_grad():\n            for val_features, val_labels in val_loader:\n                val_features, val_labels = val_features.to(device), val_labels.to(device)\n                val_outputs = model(val_features)\n                _, val_predicted = torch.max(val_outputs, 1)\n                val_correct_predictions += (val_predicted == val_labels[:, -1].long()).sum().item()\n                val_total_samples += val_labels.size(0)\n        \n        val_accuracy = val_correct_predictions / val_total_samples\n        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n\n        # Save the model after each epoch\n        torch.save(model.state_dict(), \"/kaggle/working/attention_modal.pth\")\n        print(f\"Model saved \")\n\n# # Define the input size and number of classes\n# input_size = 6  # Number of features in the input data\n# hidden_size = 64  # Hidden size of the LSTM and attention mechanism\n# num_classes = 4  # Number of classes (0, 1, 2, 3)\n\n# # Initialize the model\n# attention_model = EMGAttentionModel(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes)\n\n# Assuming your EMGDataset, train_loader, val_loader are defined earlier\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\noptimizer = torch.optim.Adam(attention_model.parameters(), lr=0.001)\n\n# Train the model and save it\ntrain_model_attention(attention_model, train_loader, val_loader, criterion, optimizer, model_path='/kaggle/input/emg-fin-model-pth/attention_model.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T18:53:37.636766Z","iopub.execute_input":"2024-03-16T18:53:37.637599Z","iopub.status.idle":"2024-03-16T19:00:41.395668Z","shell.execute_reply.started":"2024-03-16T18:53:37.637569Z","shell.execute_reply":"2024-03-16T19:00:41.394767Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model loaded from /kaggle/input/emg-fin-model-pth/attention_model.pth\nEpoch 1/100, Train Loss: 0.5417, Train Accuracy: 0.8504\nValidation Accuracy: 0.8667\nModel saved \nEpoch 2/100, Train Loss: 0.3868, Train Accuracy: 0.8790\nValidation Accuracy: 0.8792\nModel saved \nEpoch 3/100, Train Loss: 0.3707, Train Accuracy: 0.8839\nValidation Accuracy: 0.8729\nModel saved \nEpoch 4/100, Train Loss: 0.3570, Train Accuracy: 0.8848\nValidation Accuracy: 0.8667\nModel saved \nEpoch 5/100, Train Loss: 0.2767, Train Accuracy: 0.9089\nValidation Accuracy: 0.8750\nModel saved \nEpoch 6/100, Train Loss: 0.2804, Train Accuracy: 0.9013\nValidation Accuracy: 0.8708\nModel saved \nEpoch 7/100, Train Loss: 0.2452, Train Accuracy: 0.9121\nValidation Accuracy: 0.8625\nModel saved \nEpoch 8/100, Train Loss: 0.2846, Train Accuracy: 0.8996\nValidation Accuracy: 0.8479\nModel saved \nEpoch 9/100, Train Loss: 0.2851, Train Accuracy: 0.9067\nValidation Accuracy: 0.8604\nModel saved \nEpoch 10/100, Train Loss: 0.2283, Train Accuracy: 0.9237\nValidation Accuracy: 0.8500\nModel saved \nEpoch 11/100, Train Loss: 0.2362, Train Accuracy: 0.9179\nValidation Accuracy: 0.8646\nModel saved \nEpoch 12/100, Train Loss: 0.2569, Train Accuracy: 0.9129\nValidation Accuracy: 0.8375\nModel saved \nEpoch 13/100, Train Loss: 0.2488, Train Accuracy: 0.9147\nValidation Accuracy: 0.8688\nModel saved \nEpoch 14/100, Train Loss: 0.2447, Train Accuracy: 0.9228\nValidation Accuracy: 0.8542\nModel saved \nEpoch 15/100, Train Loss: 0.1867, Train Accuracy: 0.9353\nValidation Accuracy: 0.8812\nModel saved \nEpoch 16/100, Train Loss: 0.2190, Train Accuracy: 0.9250\nValidation Accuracy: 0.8604\nModel saved \nEpoch 17/100, Train Loss: 0.2254, Train Accuracy: 0.9228\nValidation Accuracy: 0.8458\nModel saved \nEpoch 18/100, Train Loss: 0.1895, Train Accuracy: 0.9344\nValidation Accuracy: 0.8521\nModel saved \nEpoch 19/100, Train Loss: 0.2061, Train Accuracy: 0.9290\nValidation Accuracy: 0.8458\nModel saved \nEpoch 20/100, Train Loss: 0.1972, Train Accuracy: 0.9348\nValidation Accuracy: 0.8438\nModel saved \nEpoch 21/100, Train Loss: 0.2190, Train Accuracy: 0.9295\nValidation Accuracy: 0.8375\nModel saved \nEpoch 22/100, Train Loss: 0.2184, Train Accuracy: 0.9241\nValidation Accuracy: 0.8542\nModel saved \nEpoch 23/100, Train Loss: 0.1826, Train Accuracy: 0.9366\nValidation Accuracy: 0.8562\nModel saved \nEpoch 24/100, Train Loss: 0.1836, Train Accuracy: 0.9362\nValidation Accuracy: 0.8146\nModel saved \nEpoch 25/100, Train Loss: 0.1917, Train Accuracy: 0.9308\nValidation Accuracy: 0.8583\nModel saved \nEpoch 26/100, Train Loss: 0.1869, Train Accuracy: 0.9348\nValidation Accuracy: 0.8500\nModel saved \nEpoch 27/100, Train Loss: 0.2263, Train Accuracy: 0.9295\nValidation Accuracy: 0.7833\nModel saved \nEpoch 28/100, Train Loss: 0.2248, Train Accuracy: 0.9205\nValidation Accuracy: 0.8438\nModel saved \nEpoch 29/100, Train Loss: 0.1667, Train Accuracy: 0.9437\nValidation Accuracy: 0.8417\nModel saved \nEpoch 30/100, Train Loss: 0.2351, Train Accuracy: 0.9326\nValidation Accuracy: 0.7917\nModel saved \nEpoch 31/100, Train Loss: 0.2946, Train Accuracy: 0.8893\nValidation Accuracy: 0.8292\nModel saved \nEpoch 32/100, Train Loss: 0.2227, Train Accuracy: 0.9201\nValidation Accuracy: 0.8479\nModel saved \nEpoch 33/100, Train Loss: 0.2129, Train Accuracy: 0.9335\nValidation Accuracy: 0.8333\nModel saved \nEpoch 34/100, Train Loss: 0.1990, Train Accuracy: 0.9290\nValidation Accuracy: 0.8250\nModel saved \nEpoch 35/100, Train Loss: 0.1740, Train Accuracy: 0.9371\nValidation Accuracy: 0.8479\nModel saved \nEpoch 36/100, Train Loss: 0.1641, Train Accuracy: 0.9362\nValidation Accuracy: 0.8375\nModel saved \nEpoch 37/100, Train Loss: 0.1693, Train Accuracy: 0.9415\nValidation Accuracy: 0.8375\nModel saved \nEpoch 38/100, Train Loss: 0.1761, Train Accuracy: 0.9393\nValidation Accuracy: 0.8542\nModel saved \nEpoch 39/100, Train Loss: 0.1536, Train Accuracy: 0.9460\nValidation Accuracy: 0.8458\nModel saved \nEpoch 40/100, Train Loss: 0.1480, Train Accuracy: 0.9437\nValidation Accuracy: 0.8688\nModel saved \nEpoch 41/100, Train Loss: 0.1680, Train Accuracy: 0.9411\nValidation Accuracy: 0.8417\nModel saved \nEpoch 42/100, Train Loss: 0.1555, Train Accuracy: 0.9464\nValidation Accuracy: 0.8271\nModel saved \nEpoch 43/100, Train Loss: 0.1687, Train Accuracy: 0.9348\nValidation Accuracy: 0.8146\nModel saved \nEpoch 44/100, Train Loss: 0.1897, Train Accuracy: 0.9348\nValidation Accuracy: 0.8250\nModel saved \nEpoch 45/100, Train Loss: 0.2998, Train Accuracy: 0.8951\nValidation Accuracy: 0.8104\nModel saved \nEpoch 46/100, Train Loss: 0.2322, Train Accuracy: 0.9196\nValidation Accuracy: 0.7875\nModel saved \nEpoch 47/100, Train Loss: 0.1834, Train Accuracy: 0.9317\nValidation Accuracy: 0.8042\nModel saved \nEpoch 48/100, Train Loss: 0.1754, Train Accuracy: 0.9362\nValidation Accuracy: 0.8333\nModel saved \nEpoch 49/100, Train Loss: 0.1439, Train Accuracy: 0.9527\nValidation Accuracy: 0.8354\nModel saved \nEpoch 50/100, Train Loss: 0.1435, Train Accuracy: 0.9504\nValidation Accuracy: 0.8083\nModel saved \nEpoch 51/100, Train Loss: 0.1563, Train Accuracy: 0.9464\nValidation Accuracy: 0.7958\nModel saved \nEpoch 52/100, Train Loss: 0.2028, Train Accuracy: 0.9335\nValidation Accuracy: 0.7833\nModel saved \nEpoch 53/100, Train Loss: 0.1850, Train Accuracy: 0.9371\nValidation Accuracy: 0.7792\nModel saved \nEpoch 54/100, Train Loss: 0.3258, Train Accuracy: 0.8844\nValidation Accuracy: 0.7750\nModel saved \nEpoch 55/100, Train Loss: 0.2426, Train Accuracy: 0.9205\nValidation Accuracy: 0.8042\nModel saved \nEpoch 56/100, Train Loss: 0.1639, Train Accuracy: 0.9429\nValidation Accuracy: 0.8125\nModel saved \nEpoch 57/100, Train Loss: 0.1529, Train Accuracy: 0.9420\nValidation Accuracy: 0.8125\nModel saved \nEpoch 58/100, Train Loss: 0.1537, Train Accuracy: 0.9411\nValidation Accuracy: 0.8063\nModel saved \nEpoch 59/100, Train Loss: 0.1386, Train Accuracy: 0.9496\nValidation Accuracy: 0.8000\nModel saved \nEpoch 60/100, Train Loss: 0.1750, Train Accuracy: 0.9415\nValidation Accuracy: 0.7937\nModel saved \nEpoch 61/100, Train Loss: 0.1598, Train Accuracy: 0.9464\nValidation Accuracy: 0.8063\nModel saved \nEpoch 62/100, Train Loss: 0.1570, Train Accuracy: 0.9460\nValidation Accuracy: 0.8042\nModel saved \nEpoch 63/100, Train Loss: 0.1288, Train Accuracy: 0.9558\nValidation Accuracy: 0.8229\nModel saved \nEpoch 64/100, Train Loss: 0.1276, Train Accuracy: 0.9549\nValidation Accuracy: 0.7958\nModel saved \nEpoch 65/100, Train Loss: 0.1740, Train Accuracy: 0.9393\nValidation Accuracy: 0.8167\nModel saved \nEpoch 66/100, Train Loss: 0.2054, Train Accuracy: 0.9272\nValidation Accuracy: 0.7917\nModel saved \nEpoch 67/100, Train Loss: 0.1837, Train Accuracy: 0.9335\nValidation Accuracy: 0.8083\nModel saved \nEpoch 68/100, Train Loss: 0.1827, Train Accuracy: 0.9375\nValidation Accuracy: 0.7937\nModel saved \nEpoch 69/100, Train Loss: 0.1687, Train Accuracy: 0.9446\nValidation Accuracy: 0.7958\nModel saved \nEpoch 70/100, Train Loss: 0.1342, Train Accuracy: 0.9513\nValidation Accuracy: 0.7937\nModel saved \nEpoch 71/100, Train Loss: 0.1240, Train Accuracy: 0.9540\nValidation Accuracy: 0.8021\nModel saved \nEpoch 72/100, Train Loss: 0.1390, Train Accuracy: 0.9531\nValidation Accuracy: 0.8000\nModel saved \nEpoch 73/100, Train Loss: 0.1179, Train Accuracy: 0.9629\nValidation Accuracy: 0.7875\nModel saved \nEpoch 74/100, Train Loss: 0.1345, Train Accuracy: 0.9513\nValidation Accuracy: 0.7896\nModel saved \nEpoch 75/100, Train Loss: 0.1142, Train Accuracy: 0.9571\nValidation Accuracy: 0.7812\nModel saved \nEpoch 76/100, Train Loss: 0.2065, Train Accuracy: 0.9281\nValidation Accuracy: 0.7958\nModel saved \nEpoch 77/100, Train Loss: 0.1803, Train Accuracy: 0.9379\nValidation Accuracy: 0.7979\nModel saved \nEpoch 78/100, Train Loss: 0.2109, Train Accuracy: 0.9228\nValidation Accuracy: 0.8042\nModel saved \nEpoch 79/100, Train Loss: 0.1774, Train Accuracy: 0.9348\nValidation Accuracy: 0.8104\nModel saved \nEpoch 80/100, Train Loss: 0.2087, Train Accuracy: 0.9246\nValidation Accuracy: 0.7854\nModel saved \nEpoch 81/100, Train Loss: 0.1615, Train Accuracy: 0.9429\nValidation Accuracy: 0.7896\nModel saved \nEpoch 82/100, Train Loss: 0.1549, Train Accuracy: 0.9473\nValidation Accuracy: 0.7917\nModel saved \nEpoch 83/100, Train Loss: 0.1479, Train Accuracy: 0.9473\nValidation Accuracy: 0.7937\nModel saved \nEpoch 84/100, Train Loss: 0.1208, Train Accuracy: 0.9540\nValidation Accuracy: 0.8042\nModel saved \nEpoch 85/100, Train Loss: 0.1056, Train Accuracy: 0.9679\nValidation Accuracy: 0.7854\nModel saved \nEpoch 86/100, Train Loss: 0.1054, Train Accuracy: 0.9616\nValidation Accuracy: 0.8042\nModel saved \nEpoch 87/100, Train Loss: 0.1023, Train Accuracy: 0.9625\nValidation Accuracy: 0.8021\nModel saved \nEpoch 88/100, Train Loss: 0.0994, Train Accuracy: 0.9612\nValidation Accuracy: 0.8021\nModel saved \nEpoch 89/100, Train Loss: 0.0813, Train Accuracy: 0.9701\nValidation Accuracy: 0.8146\nModel saved \nEpoch 90/100, Train Loss: 0.1142, Train Accuracy: 0.9589\nValidation Accuracy: 0.7896\nModel saved \nEpoch 91/100, Train Loss: 0.1089, Train Accuracy: 0.9607\nValidation Accuracy: 0.7958\nModel saved \nEpoch 92/100, Train Loss: 0.1506, Train Accuracy: 0.9536\nValidation Accuracy: 0.7937\nModel saved \nEpoch 93/100, Train Loss: 0.1168, Train Accuracy: 0.9540\nValidation Accuracy: 0.8083\nModel saved \nEpoch 94/100, Train Loss: 0.1317, Train Accuracy: 0.9522\nValidation Accuracy: 0.7729\nModel saved \nEpoch 95/100, Train Loss: 0.1104, Train Accuracy: 0.9616\nValidation Accuracy: 0.7875\nModel saved \nEpoch 96/100, Train Loss: 0.1446, Train Accuracy: 0.9451\nValidation Accuracy: 0.8083\nModel saved \nEpoch 97/100, Train Loss: 0.1289, Train Accuracy: 0.9549\nValidation Accuracy: 0.7854\nModel saved \nEpoch 98/100, Train Loss: 0.1367, Train Accuracy: 0.9496\nValidation Accuracy: 0.7875\nModel saved \nEpoch 99/100, Train Loss: 0.1233, Train Accuracy: 0.9580\nValidation Accuracy: 0.7958\nModel saved \nEpoch 100/100, Train Loss: 0.1287, Train Accuracy: 0.9549\nValidation Accuracy: 0.7958\nModel saved \n","output_type":"stream"}]},{"cell_type":"code","source":"pip install pytorch_model_summary\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:53.877567Z","iopub.execute_input":"2024-04-02T13:59:53.877966Z","iopub.status.idle":"2024-04-02T14:00:09.441489Z","shell.execute_reply.started":"2024-04-02T13:59:53.877937Z","shell.execute_reply":"2024-04-02T14:00:09.439851Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting pytorch_model_summary\n  Downloading pytorch_model_summary-0.1.2-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch_model_summary) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from pytorch_model_summary) (2.1.2+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch_model_summary) (1.24.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_model_summary) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_model_summary) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_model_summary) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_model_summary) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_model_summary) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_model_summary) (2023.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->pytorch_model_summary) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->pytorch_model_summary) (1.3.0)\nDownloading pytorch_model_summary-0.1.2-py3-none-any.whl (9.3 kB)\nInstalling collected packages: pytorch_model_summary\nSuccessfully installed pytorch_model_summary-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom pytorch_model_summary import summary\n\n# Define your model\ninput_size = 6\nhidden_size = 64\nnum_layers = 6\nbidirectional = True\nnum_classes = 4\n\nattention_model = EMGAttentionModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional, num_classes=num_classes)\n\n# Generate model summary\nmodel_summary = summary(attention_model, torch.zeros((32, 1000, input_size)))\n\n# Print model summary\nprint(model_summary)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:00:34.339034Z","iopub.execute_input":"2024-04-02T14:00:34.339469Z","iopub.status.idle":"2024-04-02T14:00:35.972278Z","shell.execute_reply.started":"2024-04-02T14:00:34.339427Z","shell.execute_reply":"2024-04-02T14:00:35.971026Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\n      Layer (type)                                    Output Shape         Param #     Tr. Param #\n===================================================================================================\n            LSTM-1     [32, 1000, 128], [12, 32, 64], [12, 32, 64]         533,504         533,504\n       LayerNorm-2                                 [32, 1000, 128]             256             256\n       Attention-3                           [32, 128], [32, 1000]          16,640          16,640\n         Dropout-4                                       [32, 128]               0               0\n          Linear-5                                       [32, 256]          33,024          33,024\n          Linear-6                                       [32, 128]          32,896          32,896\n          Linear-7                                         [32, 4]             516             516\n===================================================================================================\nTotal params: 616,836\nTrainable params: 616,836\nNon-trainable params: 0\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the input size and number of classes\ninput_size = 6  # Number of features in the input data\nhidden_size = 64  # Hidden size of the LSTM and attention mechanism\nnum_layers = 6  # Increase the number of LSTM layers\nbidirectional = True  # Whether to use bidirectional LSTMs\nnum_classes = 4  # Number of classes (0, 1, 2, 3)\n\n# Initialize the model\nattention_model = EMGAttentionModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional, num_classes=num_classes)\n\n# Load the model state dict\nattention_model.load_state_dict(torch.load('/kaggle/input/emg-fin-model-pth/attention_model.pth'))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T09:30:44.025097Z","iopub.execute_input":"2024-04-16T09:30:44.025526Z","iopub.status.idle":"2024-04-16T09:30:44.059256Z","shell.execute_reply.started":"2024-04-16T09:30:44.025486Z","shell.execute_reply":"2024-04-16T09:30:44.058341Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install torchviz","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:51:42.516215Z","iopub.execute_input":"2024-04-02T13:51:42.517127Z","iopub.status.idle":"2024-04-02T13:52:03.212302Z","shell.execute_reply.started":"2024-04-02T13:51:42.517078Z","shell.execute_reply":"2024-04-02T13:52:03.211063Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting torchviz\n  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchviz) (2.1.2+cpu)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from torchviz) (0.20.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (2023.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchviz) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchviz) (1.3.0)\nBuilding wheels for collected packages: torchviz\n  Building wheel for torchviz (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=ecd65cac712e1ddfa465b57625127bec48e3c7c51c0596b1d48457a96f17c32c\n  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\nSuccessfully built torchviz\nInstalling collected packages: torchviz\nSuccessfully installed torchviz-0.0.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torchviz import make_dot\n\n# Initialize the model\ninput_size = 6  # Number of features in the input data\nhidden_size = 64  # Hidden size of the LSTM and attention mechanism\nnum_layers = 6  # Increase the number of LSTM layers\nbidirectional = True  # Whether to use bidirectional LSTMs\nnum_classes = 4  # Number of classes (0, 1, 2, 3)\n\nattention_model = EMGAttentionModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional, num_classes=num_classes)\n\n# Generate a random input tensor with appropriate dimensions\nbatch_size = 32\nsequence_length = 10\ninput_tensor = torch.randn(batch_size, sequence_length, input_size)\n\n# Pass the input tensor through the model\noutput_tensor = attention_model(input_tensor)\n\n# Generate visualization\ndot = make_dot(output_tensor, params=dict(attention_model.named_parameters()))\n\n# Specify the file path for saving the plot\nfile_path = \"attention_model_plot.png\"\n\n# Save the plot to the specified file path\ndot.render(filename=file_path, format='png')\n\nprint(f\"Model plot saved as {file_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:53:13.856708Z","iopub.execute_input":"2024-04-02T13:53:13.857157Z","iopub.status.idle":"2024-04-02T13:53:14.410625Z","shell.execute_reply.started":"2024-04-02T13:53:13.857123Z","shell.execute_reply":"2024-04-02T13:53:14.409306Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model plot saved as attention_model_plot.png\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install neurokit2","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:48:12.042901Z","iopub.execute_input":"2024-03-17T11:48:12.043248Z","iopub.status.idle":"2024-03-17T11:48:26.806668Z","shell.execute_reply.started":"2024-03-17T11:48:12.043219Z","shell.execute_reply":"2024-03-17T11:48:26.805449Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting neurokit2\n  Downloading neurokit2-0.2.7-py2.py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.24.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from neurokit2) (2.1.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.11.4)\nRequirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.2.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from neurokit2) (3.7.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->neurokit2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->neurokit2) (3.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->neurokit2) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->neurokit2) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->neurokit2) (1.16.0)\nDownloading neurokit2-0.2.7-py2.py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: neurokit2\nSuccessfully installed neurokit2-0.2.7\n","output_type":"stream"}]},{"cell_type":"code","source":"from neurokit2 import *\nimport pandas as pd\nfs = 500\ndef process_emg_signal(emg_signal):\n    columns_to_ignore = ['Vbat', 'Trigger', 'AccX', 'AccY', 'AccZ', 'GyX', 'GyY', 'GyZ', 'fs', 'N', 'Timestamp']\n    df_processed = emg_signal.drop(columns=columns_to_ignore)\n    df_processed = df_processed.head(1000)\n    emg_signals = []\n    infos_temp = []\n    for col_name, col_data in df_processed.items():\n        emg_signal, info = emg_process(col_data, fs) \n        emg_signals.append(emg_signal)\n        infos_temp.append(info)\n\n    return emg_signals, infos_temp\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:48:29.577226Z","iopub.execute_input":"2024-03-17T11:48:29.578122Z","iopub.status.idle":"2024-03-17T11:48:31.123082Z","shell.execute_reply.started":"2024-03-17T11:48:29.578085Z","shell.execute_reply":"2024-03-17T11:48:31.122107Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"flag = True\nwhile flag:\n    emg_signal = pd.DataFrame(pd.read_csv(\"/kaggle/input/emg-fin-csv/emg_dataset_final/down/down12.csv\" , sep=';', skiprows=1, skipfooter=1, engine='python'))\n    emg_signals , infos_temp = process_emg_signal(emg_signal)\n#     emg_data = load_emg_signals_from_df_list(emg_signals)\n    flag = False","metadata":{"execution":{"iopub.status.busy":"2024-03-17T12:00:40.596103Z","iopub.execute_input":"2024-03-17T12:00:40.596737Z","iopub.status.idle":"2024-03-17T12:00:40.944241Z","shell.execute_reply.started":"2024-03-17T12:00:40.596709Z","shell.execute_reply":"2024-03-17T12:00:40.943207Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/neurokit2/emg/emg_activation.py:236: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  df_activity[\"EMG_Activity\"][x] = 1\n/opt/conda/lib/python3.10/site-packages/neurokit2/emg/emg_activation.py:241: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  df_offsets[\"EMG_Offsets\"][x] = 1\n/opt/conda/lib/python3.10/site-packages/neurokit2/emg/emg_activation.py:236: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  df_activity[\"EMG_Activity\"][x] = 1\n/opt/conda/lib/python3.10/site-packages/neurokit2/emg/emg_activation.py:241: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  df_offsets[\"EMG_Offsets\"][x] = 1\n/opt/conda/lib/python3.10/site-packages/neurokit2/emg/emg_activation.py:236: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  df_activity[\"EMG_Activity\"][x] = 1\n/opt/conda/lib/python3.10/site-packages/neurokit2/emg/emg_activation.py:241: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  df_offsets[\"EMG_Offsets\"][x] = 1\n/opt/conda/lib/python3.10/site-packages/neurokit2/emg/emg_activation.py:236: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  df_activity[\"EMG_Activity\"][x] = 1\n/opt/conda/lib/python3.10/site-packages/neurokit2/emg/emg_activation.py:241: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  df_offsets[\"EMG_Offsets\"][x] = 1\n/opt/conda/lib/python3.10/site-packages/neurokit2/emg/emg_activation.py:236: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  df_activity[\"EMG_Activity\"][x] = 1\n/opt/conda/lib/python3.10/site-packages/neurokit2/emg/emg_activation.py:241: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  df_offsets[\"EMG_Offsets\"][x] = 1\n/opt/conda/lib/python3.10/site-packages/neurokit2/events/events_find.py:118: NeuroKitWarning: No events found. Check your event_channel or adjust 'threshold' or 'keep' arguments.\n  warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport pandas as pd\n\ndef real_time_prediction(data_frames, model):\n    predictions = []\n\n    for df in data_frames:\n        # Convert the data frame to a PyTorch tensor\n        emg_tensor = torch.tensor(df.values, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n\n        # Perform prediction\n        with torch.no_grad():\n            model.eval()  # Set the model to evaluation mode\n            output = model(emg_tensor)\n\n        # Apply softmax to get class probabilities\n        probabilities = F.softmax(output, dim=1)\n        \n        # Get the predicted class\n        _, predicted_class = torch.max(output, 1)\n\n        predictions.append((probabilities, predicted_class.item()))\n\n    return predictions\n\n# Example usage:\n# Assuming 'data_frames_list' is a list of pandas data frames containing real-time EMG data\npredictions = real_time_prediction(emg_signals, attention_model)\nfor i, (probabilities, predicted_class) in enumerate(predictions):\n    print(f\"Prediction {i + 1}:\")\n    print(\"Predicted Class:\", predicted_class)\n    print(\"Class Probabilities:\", probabilities)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T12:00:51.299570Z","iopub.execute_input":"2024-03-17T12:00:51.300460Z","iopub.status.idle":"2024-03-17T12:00:51.779157Z","shell.execute_reply.started":"2024-03-17T12:00:51.300417Z","shell.execute_reply":"2024-03-17T12:00:51.778185Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Prediction 1:\nPredicted Class: 1\nClass Probabilities: tensor([[5.6258e-04, 9.9942e-01, 1.7388e-05, 2.3437e-09]])\nPrediction 2:\nPredicted Class: 1\nClass Probabilities: tensor([[1.1765e-06, 9.9999e-01, 4.3443e-06, 9.4623e-08]])\nPrediction 3:\nPredicted Class: 1\nClass Probabilities: tensor([[2.5169e-01, 7.3608e-01, 1.2165e-02, 7.1392e-05]])\nPrediction 4:\nPredicted Class: 1\nClass Probabilities: tensor([[3.7898e-01, 6.1716e-01, 3.8517e-03, 8.7548e-06]])\nPrediction 5:\nPredicted Class: 0\nClass Probabilities: tensor([[7.6438e-01, 1.9803e-02, 2.1561e-01, 2.0190e-04]])\nPrediction 6:\nPredicted Class: 1\nClass Probabilities: tensor([[1.0824e-02, 9.8917e-01, 4.5010e-06, 6.6321e-09]])\nPrediction 7:\nPredicted Class: 1\nClass Probabilities: tensor([[7.5049e-02, 9.2495e-01, 7.8908e-08, 2.0998e-11]])\nPrediction 8:\nPredicted Class: 1\nClass Probabilities: tensor([[7.8172e-03, 9.9218e-01, 1.4887e-08, 4.0329e-12]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Define a function to load EMG signals from a list of DataFrames\n# def load_emg_signals_from_df_list(df_list):\n#     # Convert each DataFrame to a tensor and append to a list\n#     tensor_list = []\n#     for df in df_list:\n#         tensor_data = torch.tensor(df.values, dtype=torch.float32)\n#         tensor_list.append(tensor_data)\n#     # Stack tensors along a new dimension to create a 3D tensor\n#     tensor_data = torch.stack(tensor_list, dim=0)\n#     return tensor_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def preprocess_input(dataframes):\n#     # Convert each dataframe to a PyTorch tensor\n#     tensors = [torch.tensor(df.values, dtype=torch.float32) for df in dataframes]\n#     # Stack the tensors along the batch dimension\n#     input_tensor = torch.stack(tensors)\n#     # Reshape the tensor to match the model's input size\n#     input_tensor = input_tensor.unsqueeze(0)  # Add batch dimension\n#     return input_tensor","metadata":{"execution":{"iopub.status.busy":"2024-03-16T13:31:58.394261Z","iopub.execute_input":"2024-03-16T13:31:58.394908Z","iopub.status.idle":"2024-03-16T13:31:58.409723Z","shell.execute_reply.started":"2024-03-16T13:31:58.394874Z","shell.execute_reply":"2024-03-16T13:31:58.408922Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"densenet + resnet","metadata":{}}]}